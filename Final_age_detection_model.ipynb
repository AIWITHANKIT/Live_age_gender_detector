{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df2e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import cvlib as cv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "585dcc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading All Saved Models\n",
    "\n",
    "gender_model = models.load_model('gender.h5')\n",
    "age_model = models.load_model('agemodel.h5')\n",
    "race_model = models.load_model('race.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ef480c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Flask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m app\u001b[38;5;241m=\u001b[39m\u001b[43mFlask\u001b[49m(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m      2\u001b[0m camera\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_frames\u001b[39m():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Flask' is not defined"
     ]
    }
   ],
   "source": [
    "#Flask and Webcam IMPLEMENTATION FOR REAL TIME PREDICTIONS ON LIVE SERVER\n",
    "app=Flask(__name__)\n",
    "camera=cv2.VideoCapture(0)\n",
    "\n",
    "def face_detection():\n",
    "    while True:\n",
    "            \n",
    "        ## read the camera frame\n",
    "        success,frame=camera.read()\n",
    "        if not success:\n",
    "            break\n",
    "        else:\n",
    "            # apply face detection\n",
    "            face, confidence = cv.detect_face(frame)\n",
    "\n",
    "\n",
    "            # loop through detected faces\n",
    "            for idx, f in enumerate(face):\n",
    "\n",
    "                # get corner points of face rectangle        \n",
    "                (startX, startY) = f[0], f[1]\n",
    "                (endX, endY) = f[2], f[3]\n",
    "\n",
    "                # draw rectangle over face\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "                \n",
    "                \n",
    "                # crop the detected face region\n",
    "                face_crop = np.copy(frame[startY:endY,startX:endX])\n",
    "                face_crop = cv2.resize(face_crop, (200, 200))\n",
    "                face_crop = face_crop / 255.0\n",
    "                face_crop = np.expand_dims(face_crop, axis = 0)\n",
    "                \n",
    "                #predictions\n",
    "                gen_pred = gender_model.predict(face_crop)\n",
    "                age_pred = age_model.predict(face_crop)\n",
    "                age_pred = np.argmax(age_pred)\n",
    "                race_pred = race_model.predict(face_crop)\n",
    "                race_pred = np.argmax(race_pred)\n",
    "\n",
    "                if gen_pred >= 0.5:\n",
    "                    gen_pred = 'female'\n",
    "                else:\n",
    "                    gen_pred = 'male'\n",
    "                    \n",
    "        # write labels and confidence above face rectangle\n",
    "                label = gen_pred,age_pred,race_pred\n",
    "                cv2.putText(frame, label, (startX, startY),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.7, (0, 255, 0), 2)\n",
    "\n",
    "            ret,buffer=cv2.imencode('.jpg',frame)\n",
    "            frame=buffer.tobytes()\n",
    "\n",
    "        yield(b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(face_detection(),mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab60ed43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
